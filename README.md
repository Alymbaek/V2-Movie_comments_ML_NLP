ğŸ¬ Spoiler Detection in Russian Movie Comments (NLP) â€” v2
ğŸ“¬ Contacts

Alymbek Ibragimov
LinkedIn: https://www.linkedin.com/in/alymbek-ibragimov-447876336/

Goal. Detect whether a Russian movie comment contains a spoiler or no_spoiler.
Stack. Python Â· scikit-learn Â· NLTK Â· razdel Â· Mystem Â· Django REST Framework Â· Gradio

This is v2: adds lemmatization + TF-IDF n-grams, a small Gradio demo (with API), and a cleaner repo structure.

âœ¨ Whatâ€™s new in v2

ğŸ§  Text processing: lowercasing â†’ Russian stop-words â†’ lemmatization (Mystem)

ğŸ”  Features: TF-IDF, n-grams (1â€“2)

ğŸ“ˆ Evaluation: train/test split + (optional) cross-validation

ğŸ§© Artifacts: spoiler_detector.pkl (model), vec.pkl (vectorizer)

ğŸ§ª Demo: Gradio UI + programmatic access via gradio_client

ğŸ§° DRF integration: minimal classifier endpoint (example below)

ğŸ“‚ Repository structure
.
â”œâ”€â”€ Movie_comments_NLP_v2.ipynb        # training & evaluation (v2)
â”œâ”€â”€ movie_comments.csv                 # sample dataset (text,label)
â”œâ”€â”€ spoiler_detector.pkl               # trained classifier
â”œâ”€â”€ vec.pkl                            # TF-IDF vectorizer (with lemmatizer analyzer)
â”œâ”€â”€ moviesite/                         # Django REST backend (DRF)
â”‚   â””â”€â”€ movie/
â”‚       â”œâ”€â”€ serializers.py             # uses model + vectorizer
â”‚       â””â”€â”€ nlp_utils.py               # lemma_tokens() (recommended)
â”œâ”€â”€ demo_app.py                        # simple Gradio demo (optional)
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md


âš ï¸ If your vectorizer was trained with a custom analyzer (e.g. lemma_tokens), 
keep the same function available at load time. 
Best practice: put it in movie/nlp_utils.py and import from there both in training and serving.

ğŸ“Š Dataset

CSV with columns: text, label where label âˆˆ {spoiler, no_spoiler}

Language: Russian

Class balance: ~50/50

Example rows:

text,label
"Ğ¤Ğ¸Ğ»ÑŒĞ¼ Ğ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğ¹, Ğ½Ğ¾ Ğ² ĞºĞ¾Ğ½Ñ†Ğµ Ğ³ĞµÑ€Ğ¾Ğ¹...",spoiler
"ĞÑ‡ĞµĞ½ÑŒ ĞºÑ€Ğ°ÑĞ¸Ğ²Ğ°Ñ ĞºĞ°Ñ€Ñ‚Ğ¸Ğ½ĞºĞ°, ÑĞ°ÑƒĞ½Ğ´ ÑÑƒĞ¿ĞµÑ€",no_spoiler
"ĞĞ½Ñ‚Ğ°Ğ³Ğ¾Ğ½Ğ¸ÑÑ‚ Ğ½Ğ° ÑĞ°Ğ¼Ğ¾Ğ¼ Ğ´ĞµĞ»Ğµ Ğ¾Ñ‚ĞµÑ† Ğ³Ğ»Ğ°Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ğ³ĞµÑ€Ğ¾Ñ",spoiler


Dataset file: movie_comments.csv

ğŸ§ª Method (v2)

Preprocessing: lowercasing, NLTK Russian stop-words, lemmatization (Mystem + razdel)

Features: TF-IDF, n-grams (1, 2)

Model: MultinomialNB (baseline)

Split: train_test_split(test_size=0.2, random_state=42)

(Optional) Cross-validation for more robust estimates

Note: very high scores may indicate an easy dataset or leakage; prefer CV and additional tests.

ğŸš€ Quickstart
1) Create environment & install deps
python -m venv .venv
source .venv/bin/activate          # Windows: .venv\Scripts\activate
pip install -r requirements.txt


If you trained on a specific scikit-learn version, pin it (e.g. scikit-learn==1.7.0) to avoid unpickle warnings.

2) Run the Gradio demo locally (optional)

demo_app.py (already in repo â€” or create):

import sys, joblib, gradio as gr
from movie.nlp_utils import lemma_tokens  # the SAME function used in training

# Make the analyzer importable if pickled as __main__.lemma_tokens
sys.modules['__main__'].lemma_tokens = lemma_tokens

vec = joblib.load('vec.pkl')
clf = joblib.load('spoiler_detector.pkl')

def predict(text: str):
    return clf.predict(vec.transform([text]))[0]

demo = gr.Interface(
    fn=predict,
    inputs=gr.Textbox(label="Comment (RU)"),
    outputs=gr.Label(label="Prediction"),
    title="Spoiler Detection (RU)"
)
demo.launch(share=True)  # share=True gives a temporary public URL


Run:

python demo_app.py


Youâ€™ll see a local UI and (with share=True) a temporary public URL like https://xxxx.gradio.live.

3) Call the demo programmatically (gradio_client)
from gradio_client import Client

client = Client("https://YOUR-SHARE-LINK.gradio.live/")
result = client.predict(
    text="ĞĞ½ ÑƒĞ¼Ğ¸Ñ€Ğ°ĞµÑ‚ Ğ² Ñ„Ğ¸Ğ½Ğ°Ğ»Ğµ...",  # your comment text
    api_name="/predict"            # keep as shown in the notebook/Demo
)
print(result)


The share link expires in ~1 week. For a permanent URL, deploy to Hugging Face Spaces (or your own host).

ğŸ§© Django REST API (DRF)

Put artifacts (spoiler_detector.pkl, vec.pkl) into the Django project base dir (or adjust paths in serializers.py).

Ensure your analyzer function is importable in Django:

moviesite/movie/nlp_utils.py (example)

import re
from razdel import tokenize
from pymystem3 import Mystem

_mystem = Mystem()

def lemma_tokens(text: str):
    text = text.lower()
    toks = []
    for t in tokenize(text):
        w = t.text
        if re.match(r'^[Ğ°-ÑÑ‘-]+$', w):
            lem = _mystem.lemmatize(w)
            if lem:
                toks.append(lem[0].strip())
    return toks


moviesite/movie/serializers.py (key part)

import os, sys, joblib
from django.conf import settings
from rest_framework import serializers
from .models import Rating
from .nlp_utils import lemma_tokens

# If pickled under __main__, also expose it
sys.modules['__main__'].lemma_tokens = lemma_tokens

BASE = settings.BASE_DIR
vec  = joblib.load(os.path.join(BASE, 'vec.pkl'))
clf  = joblib.load(os.path.join(BASE, 'spoiler_detector.pkl'))

class RatingsSimpleSerializer(serializers.ModelSerializer):
    check_comment = serializers.SerializerMethodField()

    class Meta:
        model = Rating
        fields = ['id', 'user', 'parent', 'text', 'check_comment']

    def get_check_comment(self, obj):
        return clf.predict(vec.transform([obj.text]))[0]


Run the server:

cd moviesite
python manage.py migrate
python manage.py runserver


Example request (adjust to your actual endpoint):

curl -X POST http://127.0.0.1:8000/api/check_comment/ \
  -H "Content-Type: application/json" \
  -d '{"text": "ĞĞ½ ÑƒĞ¼Ğ¸Ñ€Ğ°ĞµÑ‚ Ğ² Ñ„Ğ¸Ğ½Ğ°Ğ»Ğµ..."}'


Example response:

{"label": "spoiler"}

Accuracy ~1.00 on this small dataset; will validate with cross-validation and harder test sets in the next iteration.

ğŸ”— Programmatic Demo (from Colab)

When launching Gradio in Colab with share=True, Colab prints a temporary public URL.
Use it with gradio_client as shown above; the api_name (usually "/predict") is printed in the cell (â€œInstall the Python clientâ€¦â€ card).

ğŸ§­ Roadmap

Cross-validation + additional metrics (F1, ROC-AUC)

Better cleaning/normalization, emoji/punctuation handling

Try fastText/Sentence-BERT embeddings

Optional context-aware variant (comment + short plot summary)


Tips

If you see InconsistentVersionWarning on unpickle, either:

pin the same scikit-learn version used for training, or

retrain and resave artifacts with your current version.

To avoid custom-function pickle issues, you can save a single Pipeline (Pipeline([('vec', vectorizer), ('clf', model)])) instead of separate files.
